{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MNIST digits classification with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mnist_sample.png\" style=\"width:30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install tqdm requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using TF 1.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "print(\"We're using TF\", tf.__version__)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import grading\n",
    "\n",
    "import matplotlib_utils\n",
    "from importlib import reload\n",
    "reload(matplotlib_utils)\n",
    "\n",
    "import grading_utils\n",
    "reload(grading_utils)\n",
    "\n",
    "import keras_utils\n",
    "from keras_utils import reset_tf_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in your Coursera token and email\n",
    "To successfully submit your answers to our grader, please fill in your Coursera submission token and email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = grading.Grader(assignment_key=\"XtD7ho3TEeiHQBLWejjYAA\", \n",
    "                        all_parts=[\"9XaAS\", \"vmogZ\", \"RMv95\", \"i8bgs\", \"rE763\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"### YOUR TOKEN HERE ###\"\n",
    "COURSERA_EMAIL = \"napear@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the data\n",
    "\n",
    "In this task we have 50000 28x28 images of digits from 0 to 9.\n",
    "We will train a classifier on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import preprocessed_mnist\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = preprocessed_mnist.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [shape (50000, 28, 28)] sample patch:\n",
      " [[0.         0.29803922 0.96470588 0.98823529 0.43921569]\n",
      " [0.         0.33333333 0.98823529 0.90196078 0.09803922]\n",
      " [0.         0.33333333 0.98823529 0.8745098  0.        ]\n",
      " [0.         0.33333333 0.98823529 0.56862745 0.        ]\n",
      " [0.         0.3372549  0.99215686 0.88235294 0.        ]]\n",
      "A closeup of a sample patch:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the whole sample:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train [shape (50000,)] 10 samples:\n",
      " [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# X contains rgb values divided by 255\n",
    "print(\"X_train [shape %s] sample patch:\\n\" % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
    "print(\"A closeup of a sample patch:\")\n",
    "plt.imshow(X_train[1, 15:20, 5:10], cmap=\"Greys\")\n",
    "plt.show()\n",
    "print(\"And the whole sample:\")\n",
    "plt.imshow(X_train[1], cmap=\"Greys\")\n",
    "plt.show()\n",
    "print(\"y_train [shape %s] 10 samples:\\n\" % (str(y_train.shape)), y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model\n",
    "\n",
    "Your task is to train a linear classifier $\\vec{x} \\rightarrow y$ with SGD using TensorFlow.\n",
    "\n",
    "You will need to calculate a logit (a linear transformation) $z_k$ for each class: \n",
    "$$z_k = \\vec{x} \\cdot \\vec{w_k} + b_k \\quad k = 0..9$$\n",
    "\n",
    "And transform logits $z_k$ to valid probabilities $p_k$ with softmax: \n",
    "$$p_k = \\frac{e^{z_k}}{\\sum_{i=0}^{9}{e^{z_i}}} \\quad k = 0..9$$\n",
    "\n",
    "We will use a cross-entropy loss to train our multi-class classifier:\n",
    "$$\\text{cross-entropy}(y, p) = -\\sum_{k=0}^{9}{\\log(p_k)[y = k]}$$ \n",
    "\n",
    "where \n",
    "$$\n",
    "[x]=\\begin{cases}\n",
    "       1, \\quad \\text{if $x$ is true} \\\\\n",
    "       0, \\quad \\text{otherwise}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Cross-entropy minimization pushes $p_k$ close to 1 when $y = k$, which is what we want.\n",
    "\n",
    "Here's the plan:\n",
    "* Flatten the images (28x28 -> 784) with `X_train.reshape((X_train.shape[0], -1))` to simplify our linear model implementation\n",
    "* Use a matrix placeholder for flattened `X_train`\n",
    "* Convert `y_train` to one-hot encoded vectors that are needed for cross-entropy\n",
    "* Use a shared variable `W` for all weights (a column $\\vec{w_k}$ per class) and `b` for all biases.\n",
    "* Aim for ~0.93 validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
    "print(X_train_flat.shape)\n",
    "\n",
    "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
    "print(X_val_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]] [5 0 4]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "y_train_oh = keras.utils.to_categorical(y_train, 10)\n",
    "y_val_oh = keras.utils.to_categorical(y_val, 10)\n",
    "\n",
    "print(y_train_oh.shape)\n",
    "print(y_train_oh[:3], y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this again if you remake your graph\n",
    "s = reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters: W and b\n",
    "W = tf.Variable(initial_value=np.ones(shape=(X_train_flat.shape[1],1)), name='Weights', dtype='float32')\n",
    "b = tf.Variable(initial_value=1, name='bias', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the input data\n",
    "input_X = tf.placeholder('float32', shape=(None, X_train_flat.shape[1]), name='input_x')\n",
    "input_y = tf.placeholder('float32', shape=(None,), name='input_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "logits = tf.tensordot(input_X, W) + b\n",
    "probas = tf.nn.softmax(logits)\n",
    "classes = tf.argmax(probas)\n",
    "\n",
    "# Loss should be a scalar number: average loss over all the objects with tf.reduce_mean().\n",
    "# Use tf.nn.softmax_cross_entropy_with_logits on top of one-hot encoded input_y and logits.\n",
    "# It is identical to calculating cross-entropy on top of probas, but is more numerically friendly (read the docs).\n",
    "loss = ### YOUR CODE HERE ### cross-entropy loss\n",
    "\n",
    "# Use a default tf.train.AdamOptimizer to get an SGD step\n",
    "step = ### YOUR CODE HERE ### optimizer step that minimizes the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 40\n",
    "\n",
    "# for logging the progress right here in Jupyter (for those who don't have TensorBoard)\n",
    "simpleTrainingCurves = matplotlib_utils.SimpleTrainingCurves(\"cross-entropy\", \"accuracy\")\n",
    "\n",
    "for epoch in range(EPOCHS):  # we finish an epoch when we've looked at all training samples\n",
    "    \n",
    "    batch_losses = []\n",
    "    for batch_start in range(0, X_train_flat.shape[0], BATCH_SIZE):  # data is already shuffled\n",
    "        _, batch_loss = s.run([step, loss], {input_X: X_train_flat[batch_start:batch_start+BATCH_SIZE], \n",
    "                                             input_y: y_train_oh[batch_start:batch_start+BATCH_SIZE]})\n",
    "        # collect batch losses, this is almost free as we need a forward pass for backprop anyway\n",
    "        batch_losses.append(batch_loss)\n",
    "\n",
    "    train_loss = np.mean(batch_losses)\n",
    "    val_loss = s.run(loss, {input_X: X_val_flat, input_y: y_val_oh})  # this part is usually small\n",
    "    train_accuracy = accuracy_score(y_train, s.run(classes, {input_X: X_train_flat}))  # this is slow and usually skipped\n",
    "    valid_accuracy = accuracy_score(y_val, s.run(classes, {input_X: X_val_flat}))  \n",
    "    simpleTrainingCurves.add(train_loss, val_loss, train_accuracy, valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, DO NOT CHANGE!\n",
    "# Testing shapes \n",
    "grader.set_answer(\"9XaAS\", grading_utils.get_tensors_shapes_string([W, b, input_X, input_y, logits, probas, classes]))\n",
    "# Validation loss\n",
    "grader.set_answer(\"vmogZ\", s.run(loss, {input_X: X_val_flat, input_y: y_val_oh}))\n",
    "# Validation accuracy\n",
    "grader.set_answer(\"RMv95\", accuracy_score(y_val, s.run(classes, {input_X: X_val_flat})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can make submission with answers so far to check yourself at this stage\n",
    "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we've coded a dense layer with matrix multiplication by hand. \n",
    "But this is not convenient, you have to create a lot of variables and your code becomes a mess. \n",
    "In TensorFlow there's an easier way to make a dense layer:\n",
    "```python\n",
    "hidden1 = tf.layers.dense(inputs, 256, activation=tf.nn.sigmoid)\n",
    "```\n",
    "\n",
    "That will create all the necessary variables automatically.\n",
    "Here you can also choose an activation function (remember that we need it for a hidden layer!).\n",
    "\n",
    "Now define the MLP with 2 hidden layers and restart training with the cell above.\n",
    "\n",
    "You're aiming for ~0.97 validation accuracy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the code here to get a new `step` operation and then run the cell with training loop above.\n",
    "# name your variables in the same way (e.g. logits, probas, classes, etc) for safety.\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit the MLP with 2 hidden layers\n",
    "Run these cells after training the MLP with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, DO NOT CHANGE!\n",
    "# Validation loss for MLP\n",
    "grader.set_answer(\"i8bgs\", s.run(loss, {input_X: X_val_flat, input_y: y_val_oh}))\n",
    "# Validation accuracy for MLP\n",
    "grader.set_answer(\"rE763\", accuracy_score(y_val, s.run(classes, {input_X: X_val_flat})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can make submission with answers so far to check yourself at this stage\n",
    "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
